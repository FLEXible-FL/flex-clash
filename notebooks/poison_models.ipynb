{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEX-clash: how to poison a model\n",
    "\n",
    "In this notebook, we will show how easy is to manipulate the model of a client using `flexclash`. Particularly, we show the usage of the decorator `@model_poisoned`, that allow us to easily modify the model of a client inside `FlexPool`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first example, we will create a federated setup using MNIST with flex primitives and then poison the model of a client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:43:48.921086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 15:43:49.031968: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-26 15:43:49.037338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-02-26 15:43:49.037354: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-02-26 15:43:49.055665: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 15:43:49.470186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-26 15:43:49.470267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-02-26 15:43:49.470281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[36m[sultan]: md5 -q ./emnist-digits.mat;\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | NoneType: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ STDERR }-------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | /bin/sh: 1: md5: not found\u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[01;31m[sultan]: Unable to run 'md5 -q ./emnist-digits.mat;'\u001b[0m\n",
      "\u001b[01;31m[sultan]: --{ TRACEBACK }----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[01;31m[sultan]: | Traceback (most recent call last):\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/api.py\", line 212, in run\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     result = Result(process, commands, self._context, streaming, halt_on_nonzero=halt_on_nonzero)\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 59, in __init__\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     self.dump_exception()\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 114, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise self._exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |   File \"/home/mariogmarq/miniconda3/lib/python3.10/site-packages/sultan/result.py\", line 95, in dump_exception\u001b[0m\n",
      "\u001b[01;31m[sultan]: |     raise subprocess.CalledProcessError(self.rc, ''.join(self._commands), self.stderr)\u001b[0m\n",
      "\u001b[01;31m[sultan]: | subprocess.CalledProcessError: Command 'md5 -q ./emnist-digits.mat;' returned non-zero exit status 127.\u001b[0m\n",
      "\u001b[01;31m[sultan]: | \u001b[0m\n",
      "\u001b[01;31m[sultan]: -------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[33m[sultan]: The following are additional information that can be used to debug this exception.\u001b[0m\n",
      "\u001b[33m[sultan]: The following is the context used to run:\u001b[0m\n",
      "\u001b[33m[sultan]: \t - cwd: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - sudo: False\u001b[0m\n",
      "\u001b[33m[sultan]: \t - user: mariogmarq\u001b[0m\n",
      "\u001b[33m[sultan]: \t - hostname: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - env: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - logging: True\u001b[0m\n",
      "\u001b[33m[sultan]: \t - executable: None\u001b[0m\n",
      "\u001b[33m[sultan]: \t - ssh_config: \u001b[0m\n",
      "\u001b[33m[sultan]: \t - src: None\u001b[0m\n",
      "\u001b[36m[sultan]: md5sum ./emnist-digits.mat | cut -f 1 -d \" \";\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from flex.datasets import load\n",
    "import tensorflow as tf\n",
    "\n",
    "flex_dataset = load(\"federated_emnist\", return_test=False, split=\"digits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the pool 3580: 1 server plus 3579 clients. The server is also an aggregator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 15:43:51.719143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-02-26 15:43:51.719191: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-02-26 15:43:51.719208: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mariogmarq): /proc/driver/nvidia/version does not exist\n",
      "2024-02-26 15:43:51.719408: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from flex.pool import FlexPool\n",
    "from flex.pool.primitives_tf import init_server_model_tf\n",
    "\n",
    "\n",
    "#Â Defining the model\n",
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "flex_pool = FlexPool.client_server_pool(fed_dataset=flex_dataset, init_func=init_server_model_tf, model=get_model())\n",
    "\n",
    "clients = flex_pool.clients\n",
    "server = flex_pool.servers\n",
    "aggregator = flex_pool.aggregators\n",
    "\n",
    "print(f\"Number of nodes in the pool {len(flex_pool)}: {len(server)} server plus {len(clients)} clients. The server is also an aggregator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flex.pool.primitives_tf import deploy_server_model_tf\n",
    "\n",
    "#Select clients\n",
    "clients_per_round=20\n",
    "selected_clients_pool = flex_pool.clients.select(clients_per_round)\n",
    "\n",
    "server.map(deploy_server_model_tf, selected_clients_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f738770c4c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f7375e87370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "from flex.pool.primitives_tf import train_tf\n",
    "\n",
    "selected_clients_pool.map(train_tf, batch_size=512, epochs=1, verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just before sending the client's weights to the aggregator/server, we will randomize the weights of one random client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f4e9fdfb-bffc-48dc-9c7f-1ba654a1c38b/assets\n"
     ]
    }
   ],
   "source": [
    "from flexclash.model import model_poisoner\n",
    "from flex.model import FlexModel\n",
    "import numpy as np\n",
    "\n",
    "randomized_weights_client = selected_clients_pool.select(1)\n",
    "\n",
    "@model_poisoner\n",
    "def weight_randomizer(client_model: FlexModel):\n",
    "    rand_weights = [np.random.randn(*w.shape) for w in client_model[\"model\"].get_weights()]\n",
    "    client_model[\"model\"].set_weights(rand_weights)\n",
    "    return client_model\n",
    "\n",
    "randomized_weights_client.map(weight_randomizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
